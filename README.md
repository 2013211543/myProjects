#### myProjects
some demos of my projects

# demo1 **Texture mapping and rendering based on OpenGL**
护手霜|手办1|大佛|手办2
---|:--:|:---:|:---:
![](https://github.com/2013211543/myProjects/blob/master/demos/hushoushuang.gif)|![](https://github.com/2013211543/myProjects/blob/master/demos/kona2.gif)|![](https://github.com/2013211543/myProjects/blob/master/demos/dafo.gif)|![](https://github.com/2013211543/myProjects/blob/master/demos/duncan2.gif)

**1. introduction**
- From this picture we can know why we need texture mapping,as you can see,vertex-coloring model seems blurry,even if you take 16 times refinement,the texture-mapping model still seems much more clear


<p align="center">
    <img src="https://github.com/2013211543/myProjects/blob/master/demos/whytexturemapping.png" alt="Sample"  width="450" height="340">
    <p align="center">
        <em>🥇 vertex-coloring  🥈 16times refine vertex-coloring  🥉 texture-mapping</em>
    </p>
</p>


---
# demo2  **Interactive Bullet Time**
result|interact demo
---|:--:
![](https://github.com/2013211543/myProjects/blob/master/demos/0115-2.gif)|![](https://github.com/2013211543/myProjects/blob/master/demos/0115.gif)

**1. introduction**
- Build multi-camera system,then capture photos Synchronously,rectfy photos,and render them in interactive panel finally
![multi-camera system](https://github.com/2013211543/myProjects/blob/master/demos/12.jpg)
- This system was built in Beijing for GUARDIAN ART CENTER[嘉德艺术中心](http://www.cguardianart.com/shows.php?id=25)
![multi-camera system](https://github.com/2013211543/myProjects/blob/master/demos/大雅宝.png)

---
# demo3  **Free viewpoint of video**
Original|Render in new scene
---|:--:
![](https://github.com/2013211543/myProjects/blob/master/demos/0114-2.gif)|![](https://github.com/2013211543/myProjects/blob/master/demos/0114.gif)

**1. introduction**
- Different from the Bullet Time mentioned above,this is a dynamic time video which you can select any viewpoint they like in a view range,just slide the silder on the left side
- The silder on the left side represents the viewpoint(space),the silder on the bottom represents time

---
# demo4  **Face reconstruction based on Deep Learning**

## reconstruction from single photo
- you can just take one front photo as input,without 1s you can get your 3d face

input|output
---|:--:
![](https://github.com/2013211543/myProjects/blob/master/demos/yidi.jpg)|![](https://github.com/2013211543/myProjects/blob/master/demos/demo1.gif)


---
# demo5  **Face swap**

### just for fun

original|reference1|reference2
---|:--:|:--:
 null|![](https://github.com/2013211543/myProjects/blob/master/demos/lyf.png)|![](https://github.com/2013211543/myProjects/blob/master/demos/tlp.jpg)
 ![](https://github.com/2013211543/myProjects/blob/master/demos/demo3small.gif)|![](https://github.com/2013211543/myProjects/blob/master/demos/demo3-1small.gif)|![](https://github.com/2013211543/myProjects/blob/master/demos/demo3-2small.gif)

